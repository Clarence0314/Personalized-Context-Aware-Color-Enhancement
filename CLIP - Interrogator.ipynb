{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce GTX 1650 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name())\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Create a tensor on the CPU\n",
    "tensor = torch.randn((3, 3))\n",
    "#Move the tensor to the GPU\n",
    "tensor = tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #@title Setup\n",
    "import os, subprocess\n",
    "\n",
    "def setup():\n",
    "    install_cmds = [\n",
    "        ['pip', 'install', 'gradio'],\n",
    "        ['pip', 'install', 'open_clip_torch'],\n",
    "        ['pip', 'install', 'clip-interrogator'],\n",
    "    ]\n",
    "    for cmd in install_cmds:\n",
    "        print(subprocess.run(cmd, stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
    "\n",
    "setup()\n",
    "\n",
    "\n",
    "caption_model_name = 'blip-large' #@param [\"blip-base\", \"blip-large\", \"git-large-coco\"]\n",
    "clip_model_name = 'ViT-L-14/openai' #@param [\"ViT-L-14/openai\", \"ViT-H-14/laion2b_s32b_b79k\"]\n",
    "\n",
    "import gradio as gr\n",
    "from clip_interrogator import Config, Interrogator\n",
    "\n",
    "config = Config()\n",
    "config.clip_model_name = clip_model_name\n",
    "config.caption_model_name = caption_model_name\n",
    "ci = Interrogator(config)\n",
    "\n",
    "def image_analysis(image):\n",
    "    image = image.convert('RGB')\n",
    "    image_features = ci.image_to_features(image)\n",
    "\n",
    "    top_mediums = ci.mediums.rank(image_features, 5)\n",
    "    top_artists = ci.artists.rank(image_features, 5)\n",
    "    top_movements = ci.movements.rank(image_features, 5)\n",
    "    top_trendings = ci.trendings.rank(image_features, 5)\n",
    "    top_flavors = ci.flavors.rank(image_features, 5)\n",
    "\n",
    "    medium_ranks = {medium: sim for medium, sim in zip(top_mediums, ci.similarities(image_features, top_mediums))}\n",
    "    artist_ranks = {artist: sim for artist, sim in zip(top_artists, ci.similarities(image_features, top_artists))}\n",
    "    movement_ranks = {movement: sim for movement, sim in zip(top_movements, ci.similarities(image_features, top_movements))}\n",
    "    trending_ranks = {trending: sim for trending, sim in zip(top_trendings, ci.similarities(image_features, top_trendings))}\n",
    "    flavor_ranks = {flavor: sim for flavor, sim in zip(top_flavors, ci.similarities(image_features, top_flavors))}\n",
    "    \n",
    "    return medium_ranks, artist_ranks, movement_ranks, trending_ranks, flavor_ranks\n",
    "\n",
    "def image_to_prompt(image, mode):\n",
    "    ci.config.chunk_size = 2048 if ci.config.clip_model_name == \"ViT-L-14/openai\" else 1024\n",
    "    ci.config.flavor_intermediate_count = 2048 if ci.config.clip_model_name == \"ViT-L-14/openai\" else 1024\n",
    "    image = image.convert('RGB')\n",
    "    if mode == 'best':\n",
    "        return ci.interrogate(image)\n",
    "    elif mode == 'classic':\n",
    "        return ci.interrogate_classic(image)\n",
    "    elif mode == 'fast':\n",
    "        return ci.interrogate_fast(image)\n",
    "    elif mode == 'negative':\n",
    "        return ci.interrogate_negative(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Batch process a folder of images 📁 -> 📝\n",
    "\n",
    "#@markdown This will generate prompts for every image in a folder and either save results \n",
    "#@markdown to a desc.csv file in the same folder or rename the files to contain their prompts.\n",
    "#@markdown The renamed files work well for [DreamBooth extension](https://github.com/d8ahazard/sd_dreambooth_extension)\n",
    "#@markdown in the [Stable Diffusion Web UI](https://github.com/AUTOMATIC1111/stable-diffusion-webui).\n",
    "#@markdown You can use the generated csv in the [Stable Diffusion Finetuning](https://colab.research.google.com/drive/1vrh_MUSaAMaC5tsLWDxkFILKJ790Z4Bl?usp=sharing)\n",
    "\n",
    "import csv\n",
    "import os\n",
    "from IPython.display import clear_output, display\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "folder_path = \"TAD66K dataset/TAD66K/\" #@param {type:\"string\"}\n",
    "prompt_mode = 'fast' #@param [\"best\",\"fast\",\"classic\",\"negative\"]\n",
    "output_mode = 'desc.csv' #@param [\"desc.csv\",\"rename\"]\n",
    "max_filename_len = 128 #@param {type:\"integer\"}\n",
    "\n",
    "\n",
    "def sanitize_for_filename(prompt: str, max_len: int) -> str:\n",
    "    name = \"\".join(c for c in prompt if (c.isalnum() or c in \",._-! \"))\n",
    "    name = name.strip()[:(max_len-4)] # extra space for extension\n",
    "    return name\n",
    "\n",
    "ci.config.quiet = True\n",
    "\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.jpg') or f.endswith('.png')] if os.path.exists(folder_path) else []\n",
    "prompts = []\n",
    "for idx, file in enumerate(tqdm(files, desc='Generating prompts')):\n",
    "    if idx > 0 and idx % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    image = Image.open(os.path.join(folder_path, file)).convert('RGB')\n",
    "    prompt = image_to_prompt(image, prompt_mode)\n",
    "    prompts.append(prompt)\n",
    "\n",
    "    print(prompt)\n",
    "    thumb = image.copy()\n",
    "    thumb.thumbnail([256, 256])\n",
    "    display(thumb)\n",
    "\n",
    "    if output_mode == 'rename':\n",
    "        name = sanitize_for_filename(prompt, max_filename_len)\n",
    "        ext = os.path.splitext(file)[1]\n",
    "        filename = name + ext\n",
    "        idx = 1\n",
    "        while os.path.exists(os.path.join(folder_path, filename)):\n",
    "            print(f'File {filename} already exists, trying {idx+1}...')\n",
    "            filename = f\"{name}_{idx}{ext}\"\n",
    "            idx += 1\n",
    "        os.rename(os.path.join(folder_path, file), os.path.join(folder_path, filename))\n",
    "\n",
    "if len(prompts):\n",
    "    if output_mode == 'desc.csv':\n",
    "        csv_path = os.path.join(folder_path, 'desc.csv')\n",
    "        with open(csv_path, 'w', encoding='utf-8', newline='') as f:\n",
    "            w = csv.writer(f, quoting=csv.QUOTE_MINIMAL)\n",
    "            w.writerow(['image', 'prompt'])\n",
    "            for file, prompt in zip(files, prompts):\n",
    "                w.writerow([file, prompt])\n",
    "\n",
    "        print(f\"\\n\\n\\n\\nGenerated {len(prompts)} prompts and saved to {csv_path}, enjoy!\")\n",
    "    else:\n",
    "        print(f\"\\n\\n\\n\\nGenerated {len(prompts)} prompts and renamed your files, enjoy!\")\n",
    "else:\n",
    "    print(f\"Sorry, I couldn't find any images in {folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug print\n",
    "print(\"Number of Prompts:\", len(prompts))\n",
    "\n",
    "if len(prompts):\n",
    "    csv_path = os.path.join(output_mode)\n",
    "    with open(csv_path, 'w', encoding='utf-8', newline='') as f:\n",
    "        w = csv.writer(f, quoting=csv.QUOTE_MINIMAL)\n",
    "        w.writerow(['image', 'prompt'])\n",
    "        for file, prompt in zip(files[:20], prompts):\n",
    "            w.writerow([file, prompt])\n",
    "\n",
    "    print(f\"\\n\\n\\n\\nGenerated {len(prompts)} prompts and saved to {csv_path}, enjoy!\")\n",
    "else:\n",
    "    print(f\"Sorry, I couldn't find any images in {folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this import statement\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Continue from where we left off\n",
    "\n",
    "# Load the SentenceTransformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Assuming prompts is a list containing the generated prompts\n",
    "encoded_prompts = model.encode(prompts)\n",
    "\n",
    "# Debug print to check the shape of encoded prompts\n",
    "print(\"Shape of encoded prompts:\", encoded_prompts.shape)\n",
    "\n",
    "# Now you can use encoded_prompts for further processing or analysis\n",
    "\n",
    "# Modify the prompt saving part to include filenames\n",
    "csv_encoded_path = \"result/encoded_prompts.csv\"\n",
    "with open(csv_encoded_path, 'w', encoding='utf-8', newline='') as f:\n",
    "    w = csv.writer(f, quoting=csv.QUOTE_MINIMAL)\n",
    "    w.writerow(['image', 'prompt', 'encoded_representation'])\n",
    "    for file, prompt, encoded_prompt in zip(files, prompts, encoded_prompts):\n",
    "        w.writerow([file, prompt, encoded_prompt.tolist()])\n",
    "\n",
    "\n",
    "print(f\"\\nEncoded prompts saved to {csv_encoded_path}\")\n",
    "\n",
    "# Now you can continue with the rest of your code as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this import statement\n",
    "import numpy as np\n",
    "\n",
    "# Continue from where we left off\n",
    "\n",
    "# Save the encoded prompts to a NumPy file\n",
    "np.save(\"result/encoded_prompts.npy\", encoded_prompts)\n",
    "\n",
    "print(\"\\nEncoded prompts saved to encoded_prompts.npy\")\n",
    "\n",
    "# Now you can continue with the rest of your code as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example verification after loading\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(csv_encoded_path)\n",
    "print(\"Data preview:\", data.head())\n",
    "print(\"Data consistency check, Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\clip\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoded prompts: (500, 384)\n",
      "\n",
      "Encoded prompts saved to expert_encoded_test.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the SentenceTransformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Assuming the CSV file path\n",
    "input_csv_path = \"color_expert_desc_test.csv\"\n",
    "output_csv_path = \"expert_encoded_test.csv\"\n",
    "\n",
    "# Read the CSV file\n",
    "files = []\n",
    "prompts = []\n",
    "with open(input_csv_path, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # Skip header\n",
    "    for row in reader:\n",
    "        files.append(row[0])\n",
    "        prompts.append(row[1])\n",
    "\n",
    "# Encode the prompts\n",
    "encoded_prompts = model.encode(prompts)\n",
    "\n",
    "# Debug print to check the shape of encoded prompts\n",
    "print(\"Shape of encoded prompts:\", encoded_prompts.shape)\n",
    "\n",
    "# Modify the prompt saving part to include filenames and encoded representations\n",
    "with open(output_csv_path, 'w', encoding='utf-8', newline='') as f:\n",
    "    writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow(['image', 'prompt', 'encoded_representation'])\n",
    "    for file, prompt, encoded_prompt in zip(files, prompts, encoded_prompts):\n",
    "        writer.writerow([file, prompt, encoded_prompt.tolist()])\n",
    "\n",
    "print(f\"\\nEncoded prompts saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            image  \\\n",
      "0              a4501-DSC_0354.jpg   \n",
      "1    a4502-Duggan_090116_4368.jpg   \n",
      "2              a4503-kme_0411.jpg   \n",
      "3              a4504-_DGW7893.jpg   \n",
      "4              a4505-DSC_0086.jpg   \n",
      "..                            ...   \n",
      "495  a4996-Duggan_090426_7783.jpg   \n",
      "496            a4997-kme_0558.jpg   \n",
      "497  a4998-Duggan_080210_5246.jpg   \n",
      "498            a4999-DSC_0035.jpg   \n",
      "499            a5000-kme_0204.jpg   \n",
      "\n",
      "                                                prompt  \\\n",
      "0    Dominant colors in the image are: rgb(93, 89, ...   \n",
      "1    Dominant colors in the image are: rgb(62, 54, ...   \n",
      "2    Dominant colors in the image are: rgb(80, 59, ...   \n",
      "3    Dominant colors in the image are: rgb(176, 176...   \n",
      "4    Dominant colors in the image are: rgb(59, 57, ...   \n",
      "..                                                 ...   \n",
      "495  Dominant colors in the image are: rgb(191, 188...   \n",
      "496  Dominant colors in the image are: rgb(220, 226...   \n",
      "497  Dominant colors in the image are: rgb(56, 55, ...   \n",
      "498  Dominant colors in the image are: rgb(36, 33, ...   \n",
      "499  Dominant colors in the image are: rgb(64, 68, ...   \n",
      "\n",
      "                                encoded_representation  \n",
      "0    [-0.09062924236059189, 0.31293147802352905, 0....  \n",
      "1    [0.0618608333170414, 0.0863037258386612, -0.27...  \n",
      "2    [-0.13956649601459503, -0.04659513756632805, 0...  \n",
      "3    [-0.29841744899749756, 0.1715054214000702, 0.0...  \n",
      "4    [0.022952012717723846, 0.20623676478862762, 0....  \n",
      "..                                                 ...  \n",
      "495  [0.04195864871144295, -0.003369925543665886, 0...  \n",
      "496  [-0.2560538053512573, 0.239653080701828, -0.09...  \n",
      "497  [-0.06291758269071579, 0.026539189741015434, 0...  \n",
      "498  [0.06946347653865814, 0.15799817442893982, 0.1...  \n",
      "499  [0.06690698117017746, -0.12455904483795166, 0....  \n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('expert_encoded_test.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4877280,
     "sourceId": 8225715,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4768641,
     "sourceId": 8297723,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
